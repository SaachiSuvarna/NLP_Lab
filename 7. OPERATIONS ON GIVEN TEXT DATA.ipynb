{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0f79d9",
   "metadata": {},
   "source": [
    "# Stemmers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82bd1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing refers to the branch of\n",
      " computer science and more specifically the branch of \n",
      " artificial intelligence, concerned with giving computers\n",
      " the ability to understand text and spoken words in much \n",
      " the same way human beings can. Human language is filled with\n",
      " ambiguities that make it incredibly difficult to write software\n",
      " that accurately determines the intended meaning of text or voice\n",
      " data. Homonyms, homophones,sarcasm, idioms, metaphors, grammar\n",
      " and usage exceptions,variations in sentence structure. These\n",
      " just a few of the irregularities of human language that take\n",
      " humans years to learn, but that programmers must teach natural\n",
      " language driven applications to recognize and understand \n",
      " accurately from the start if those applications are going to be\n",
      " useful.\n"
     ]
    }
   ],
   "source": [
    "with open('Pgm7StemLem.txt') as f:\n",
    "    text= f.readlines()\n",
    "    text= \" \".join(text)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424ae2c",
   "metadata": {},
   "source": [
    "# PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d49982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural ---> natur\n",
      "language ---> languag\n",
      "processing ---> process\n",
      "refers ---> refer\n",
      "to ---> to\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "computer ---> comput\n",
      "science ---> scienc\n",
      "and ---> and\n",
      "more ---> more\n",
      "specifically ---> specif\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "artificial ---> artifici\n",
      "intelligence ---> intellig\n",
      ", ---> ,\n",
      "concerned ---> concern\n",
      "with ---> with\n",
      "giving ---> give\n",
      "computers ---> comput\n",
      "the ---> the\n",
      "ability ---> abil\n",
      "to ---> to\n",
      "understand ---> understand\n",
      "text ---> text\n",
      "and ---> and\n",
      "spoken ---> spoken\n",
      "words ---> word\n",
      "in ---> in\n",
      "much ---> much\n",
      "the ---> the\n",
      "same ---> same\n",
      "way ---> way\n",
      "human ---> human\n",
      "beings ---> be\n",
      "can ---> can\n",
      ". ---> .\n",
      "Human ---> human\n",
      "language ---> languag\n",
      "is ---> is\n",
      "filled ---> fill\n",
      "with ---> with\n",
      "ambiguities ---> ambigu\n",
      "that ---> that\n",
      "make ---> make\n",
      "it ---> it\n",
      "incredibly ---> incred\n",
      "difficult ---> difficult\n",
      "to ---> to\n",
      "write ---> write\n",
      "software ---> softwar\n",
      "that ---> that\n",
      "accurately ---> accur\n",
      "determines ---> determin\n",
      "the ---> the\n",
      "intended ---> intend\n",
      "meaning ---> mean\n",
      "of ---> of\n",
      "text ---> text\n",
      "or ---> or\n",
      "voice ---> voic\n",
      "data ---> data\n",
      ". ---> .\n",
      "Homonyms ---> homonym\n",
      ", ---> ,\n",
      "homophones ---> homophon\n",
      ", ---> ,\n",
      "sarcasm ---> sarcasm\n",
      ", ---> ,\n",
      "idioms ---> idiom\n",
      ", ---> ,\n",
      "metaphors ---> metaphor\n",
      ", ---> ,\n",
      "grammar ---> grammar\n",
      "and ---> and\n",
      "usage ---> usag\n",
      "exceptions ---> except\n",
      ", ---> ,\n",
      "variations ---> variat\n",
      "in ---> in\n",
      "sentence ---> sentenc\n",
      "structure ---> structur\n",
      ". ---> .\n",
      "These ---> these\n",
      "just ---> just\n",
      "a ---> a\n",
      "few ---> few\n",
      "of ---> of\n",
      "the ---> the\n",
      "irregularities ---> irregular\n",
      "of ---> of\n",
      "human ---> human\n",
      "language ---> languag\n",
      "that ---> that\n",
      "take ---> take\n",
      "humans ---> human\n",
      "years ---> year\n",
      "to ---> to\n",
      "learn ---> learn\n",
      ", ---> ,\n",
      "but ---> but\n",
      "that ---> that\n",
      "programmers ---> programm\n",
      "must ---> must\n",
      "teach ---> teach\n",
      "natural ---> natur\n",
      "language ---> languag\n",
      "driven ---> driven\n",
      "applications ---> applic\n",
      "to ---> to\n",
      "recognize ---> recogn\n",
      "and ---> and\n",
      "understand ---> understand\n",
      "accurately ---> accur\n",
      "from ---> from\n",
      "the ---> the\n",
      "start ---> start\n",
      "if ---> if\n",
      "those ---> those\n",
      "applications ---> applic\n",
      "are ---> are\n",
      "going ---> go\n",
      "to ---> to\n",
      "be ---> be\n",
      "useful ---> use\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "token= word_tokenize(text)\n",
    "\n",
    "st= PorterStemmer()\n",
    "\n",
    "for t in token:\n",
    "    print(t, '---> '+ st.stem(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30009c",
   "metadata": {},
   "source": [
    "# Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8a074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural ---> natur\n",
      "language ---> languag\n",
      "processing ---> process\n",
      "refers ---> refer\n",
      "to ---> to\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "computer ---> comput\n",
      "science ---> scienc\n",
      "and ---> and\n",
      "more ---> more\n",
      "specifically ---> specif\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "artificial ---> artifici\n",
      "intelligence ---> intellig\n",
      ", ---> ,\n",
      "concerned ---> concern\n",
      "with ---> with\n",
      "giving ---> give\n",
      "computers ---> comput\n",
      "the ---> the\n",
      "ability ---> abil\n",
      "to ---> to\n",
      "understand ---> understand\n",
      "text ---> text\n",
      "and ---> and\n",
      "spoken ---> spoken\n",
      "words ---> word\n",
      "in ---> in\n",
      "much ---> much\n",
      "the ---> the\n",
      "same ---> same\n",
      "way ---> way\n",
      "human ---> human\n",
      "beings ---> be\n",
      "can ---> can\n",
      ". ---> .\n",
      "Human ---> human\n",
      "language ---> languag\n",
      "is ---> is\n",
      "filled ---> fill\n",
      "with ---> with\n",
      "ambiguities ---> ambigu\n",
      "that ---> that\n",
      "make ---> make\n",
      "it ---> it\n",
      "incredibly ---> incred\n",
      "difficult ---> difficult\n",
      "to ---> to\n",
      "write ---> write\n",
      "software ---> softwar\n",
      "that ---> that\n",
      "accurately ---> accur\n",
      "determines ---> determin\n",
      "the ---> the\n",
      "intended ---> intend\n",
      "meaning ---> mean\n",
      "of ---> of\n",
      "text ---> text\n",
      "or ---> or\n",
      "voice ---> voic\n",
      "data ---> data\n",
      ". ---> .\n",
      "Homonyms ---> homonym\n",
      ", ---> ,\n",
      "homophones ---> homophon\n",
      ", ---> ,\n",
      "sarcasm ---> sarcasm\n",
      ", ---> ,\n",
      "idioms ---> idiom\n",
      ", ---> ,\n",
      "metaphors ---> metaphor\n",
      ", ---> ,\n",
      "grammar ---> grammar\n",
      "and ---> and\n",
      "usage ---> usag\n",
      "exceptions ---> except\n",
      ", ---> ,\n",
      "variations ---> variat\n",
      "in ---> in\n",
      "sentence ---> sentenc\n",
      "structure ---> structur\n",
      ". ---> .\n",
      "These ---> these\n",
      "just ---> just\n",
      "a ---> a\n",
      "few ---> few\n",
      "of ---> of\n",
      "the ---> the\n",
      "irregularities ---> irregular\n",
      "of ---> of\n",
      "human ---> human\n",
      "language ---> languag\n",
      "that ---> that\n",
      "take ---> take\n",
      "humans ---> human\n",
      "years ---> year\n",
      "to ---> to\n",
      "learn ---> learn\n",
      ", ---> ,\n",
      "but ---> but\n",
      "that ---> that\n",
      "programmers ---> programm\n",
      "must ---> must\n",
      "teach ---> teach\n",
      "natural ---> natur\n",
      "language ---> languag\n",
      "driven ---> driven\n",
      "applications ---> applic\n",
      "to ---> to\n",
      "recognize ---> recogn\n",
      "and ---> and\n",
      "understand ---> understand\n",
      "accurately ---> accur\n",
      "from ---> from\n",
      "the ---> the\n",
      "start ---> start\n",
      "if ---> if\n",
      "those ---> those\n",
      "applications ---> applic\n",
      "are ---> are\n",
      "going ---> go\n",
      "to ---> to\n",
      "be ---> be\n",
      "useful ---> use\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "st= SnowballStemmer('english')\n",
    "\n",
    "for t in token:\n",
    "    print(t, '---> '+ st.stem(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdeec6d",
   "metadata": {},
   "source": [
    "# LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d234b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural ---> nat\n",
      "language ---> langu\n",
      "processing ---> process\n",
      "refers ---> ref\n",
      "to ---> to\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "computer ---> comput\n",
      "science ---> sci\n",
      "and ---> and\n",
      "more ---> mor\n",
      "specifically ---> spec\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "artificial ---> art\n",
      "intelligence ---> intellig\n",
      ", ---> ,\n",
      "concerned ---> concern\n",
      "with ---> with\n",
      "giving ---> giv\n",
      "computers ---> comput\n",
      "the ---> the\n",
      "ability ---> abl\n",
      "to ---> to\n",
      "understand ---> understand\n",
      "text ---> text\n",
      "and ---> and\n",
      "spoken ---> spok\n",
      "words ---> word\n",
      "in ---> in\n",
      "much ---> much\n",
      "the ---> the\n",
      "same ---> sam\n",
      "way ---> way\n",
      "human ---> hum\n",
      "beings ---> being\n",
      "can ---> can\n",
      ". ---> .\n",
      "Human ---> hum\n",
      "language ---> langu\n",
      "is ---> is\n",
      "filled ---> fil\n",
      "with ---> with\n",
      "ambiguities ---> ambigu\n",
      "that ---> that\n",
      "make ---> mak\n",
      "it ---> it\n",
      "incredibly ---> incred\n",
      "difficult ---> difficult\n",
      "to ---> to\n",
      "write ---> writ\n",
      "software ---> softw\n",
      "that ---> that\n",
      "accurately ---> acc\n",
      "determines ---> determin\n",
      "the ---> the\n",
      "intended ---> intend\n",
      "meaning ---> mean\n",
      "of ---> of\n",
      "text ---> text\n",
      "or ---> or\n",
      "voice ---> voic\n",
      "data ---> dat\n",
      ". ---> .\n",
      "Homonyms ---> homonym\n",
      ", ---> ,\n",
      "homophones ---> homophon\n",
      ", ---> ,\n",
      "sarcasm ---> sarcasm\n",
      ", ---> ,\n",
      "idioms ---> idiom\n",
      ", ---> ,\n",
      "metaphors ---> metaph\n",
      ", ---> ,\n",
      "grammar ---> gramm\n",
      "and ---> and\n",
      "usage ---> us\n",
      "exceptions ---> exceiv\n",
      ", ---> ,\n",
      "variations ---> vary\n",
      "in ---> in\n",
      "sentence ---> sent\n",
      "structure ---> structure\n",
      ". ---> .\n",
      "These ---> thes\n",
      "just ---> just\n",
      "a ---> a\n",
      "few ---> few\n",
      "of ---> of\n",
      "the ---> the\n",
      "irregularities ---> irregul\n",
      "of ---> of\n",
      "human ---> hum\n",
      "language ---> langu\n",
      "that ---> that\n",
      "take ---> tak\n",
      "humans ---> hum\n",
      "years ---> year\n",
      "to ---> to\n",
      "learn ---> learn\n",
      ", ---> ,\n",
      "but ---> but\n",
      "that ---> that\n",
      "programmers ---> program\n",
      "must ---> must\n",
      "teach ---> teach\n",
      "natural ---> nat\n",
      "language ---> langu\n",
      "driven ---> driv\n",
      "applications ---> apply\n",
      "to ---> to\n",
      "recognize ---> recogn\n",
      "and ---> and\n",
      "understand ---> understand\n",
      "accurately ---> acc\n",
      "from ---> from\n",
      "the ---> the\n",
      "start ---> start\n",
      "if ---> if\n",
      "those ---> thos\n",
      "applications ---> apply\n",
      "are ---> ar\n",
      "going ---> going\n",
      "to ---> to\n",
      "be ---> be\n",
      "useful ---> us\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "st= LancasterStemmer()\n",
    "\n",
    "for t in token:\n",
    "    print(t, '---> '+ st.stem(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603c9b3",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fafad01",
   "metadata": {},
   "source": [
    "# Spacy Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9281ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural ---> natural\n",
      "language ---> language\n",
      "processing ---> processing\n",
      "refers ---> refer\n",
      "to ---> to\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "\n",
      "  ---> \n",
      " \n",
      "computer ---> computer\n",
      "science ---> science\n",
      "and ---> and\n",
      "more ---> more\n",
      "specifically ---> specifically\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "\n",
      "  ---> \n",
      " \n",
      "artificial ---> artificial\n",
      "intelligence ---> intelligence\n",
      ", ---> ,\n",
      "concerned ---> concern\n",
      "with ---> with\n",
      "giving ---> give\n",
      "computers ---> computer\n",
      "\n",
      "  ---> \n",
      " \n",
      "the ---> the\n",
      "ability ---> ability\n",
      "to ---> to\n",
      "understand ---> understand\n",
      "text ---> text\n",
      "and ---> and\n",
      "spoken ---> spoken\n",
      "words ---> word\n",
      "in ---> in\n",
      "much ---> much\n",
      "\n",
      "  ---> \n",
      " \n",
      "the ---> the\n",
      "same ---> same\n",
      "way ---> way\n",
      "human ---> human\n",
      "beings ---> being\n",
      "can ---> can\n",
      ". ---> .\n",
      "Human ---> human\n",
      "language ---> language\n",
      "is ---> be\n",
      "filled ---> fill\n",
      "with ---> with\n",
      "\n",
      "  ---> \n",
      " \n",
      "ambiguities ---> ambiguity\n",
      "that ---> that\n",
      "make ---> make\n",
      "it ---> it\n",
      "incredibly ---> incredibly\n",
      "difficult ---> difficult\n",
      "to ---> to\n",
      "write ---> write\n",
      "software ---> software\n",
      "\n",
      "  ---> \n",
      " \n",
      "that ---> that\n",
      "accurately ---> accurately\n",
      "determines ---> determine\n",
      "the ---> the\n",
      "intended ---> intend\n",
      "meaning ---> meaning\n",
      "of ---> of\n",
      "text ---> text\n",
      "or ---> or\n",
      "voice ---> voice\n",
      "\n",
      "  ---> \n",
      " \n",
      "data ---> datum\n",
      ". ---> .\n",
      "Homonyms ---> Homonyms\n",
      ", ---> ,\n",
      "homophones ---> homophone\n",
      ", ---> ,\n",
      "sarcasm ---> sarcasm\n",
      ", ---> ,\n",
      "idioms ---> idiom\n",
      ", ---> ,\n",
      "metaphors ---> metaphor\n",
      ", ---> ,\n",
      "grammar ---> grammar\n",
      "\n",
      "  ---> \n",
      " \n",
      "and ---> and\n",
      "usage ---> usage\n",
      "exceptions ---> exception\n",
      ", ---> ,\n",
      "variations ---> variation\n",
      "in ---> in\n",
      "sentence ---> sentence\n",
      "structure ---> structure\n",
      ". ---> .\n",
      "These ---> these\n",
      "\n",
      "  ---> \n",
      " \n",
      "just ---> just\n",
      "a ---> a\n",
      "few ---> few\n",
      "of ---> of\n",
      "the ---> the\n",
      "irregularities ---> irregularity\n",
      "of ---> of\n",
      "human ---> human\n",
      "language ---> language\n",
      "that ---> that\n",
      "take ---> take\n",
      "\n",
      "  ---> \n",
      " \n",
      "humans ---> human\n",
      "years ---> year\n",
      "to ---> to\n",
      "learn ---> learn\n",
      ", ---> ,\n",
      "but ---> but\n",
      "that ---> that\n",
      "programmers ---> programmer\n",
      "must ---> must\n",
      "teach ---> teach\n",
      "natural ---> natural\n",
      "\n",
      "  ---> \n",
      " \n",
      "language ---> language\n",
      "driven ---> drive\n",
      "applications ---> application\n",
      "to ---> to\n",
      "recognize ---> recognize\n",
      "and ---> and\n",
      "understand ---> understand\n",
      "\n",
      "  ---> \n",
      " \n",
      "accurately ---> accurately\n",
      "from ---> from\n",
      "the ---> the\n",
      "start ---> start\n",
      "if ---> if\n",
      "those ---> those\n",
      "applications ---> application\n",
      "are ---> be\n",
      "going ---> go\n",
      "to ---> to\n",
      "be ---> be\n",
      "\n",
      "  ---> \n",
      " \n",
      "useful ---> useful\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp= spacy.load('en_core_web_sm')\n",
    "doc= nlp(text)\n",
    "\n",
    "for i in doc:\n",
    "    print(i, '---> '+ i.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324367c1",
   "metadata": {},
   "source": [
    "# WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acc9744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural ---> Natural\n",
      "language ---> language\n",
      "processing ---> processing\n",
      "refers ---> refers\n",
      "to ---> to\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "computer ---> computer\n",
      "science ---> science\n",
      "and ---> and\n",
      "more ---> more\n",
      "specifically ---> specifically\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "artificial ---> artificial\n",
      "intelligence ---> intelligence\n",
      ", ---> ,\n",
      "concerned ---> concerned\n",
      "with ---> with\n",
      "giving ---> giving\n",
      "computers ---> computer\n",
      "the ---> the\n",
      "ability ---> ability\n",
      "to ---> to\n",
      "understand ---> understand\n",
      "text ---> text\n",
      "and ---> and\n",
      "spoken ---> spoken\n",
      "words ---> word\n",
      "in ---> in\n",
      "much ---> much\n",
      "the ---> the\n",
      "same ---> same\n",
      "way ---> way\n",
      "human ---> human\n",
      "beings ---> being\n",
      "can ---> can\n",
      ". ---> .\n",
      "Human ---> Human\n",
      "language ---> language\n",
      "is ---> is\n",
      "filled ---> filled\n",
      "with ---> with\n",
      "ambiguities ---> ambiguity\n",
      "that ---> that\n",
      "make ---> make\n",
      "it ---> it\n",
      "incredibly ---> incredibly\n",
      "difficult ---> difficult\n",
      "to ---> to\n",
      "write ---> write\n",
      "software ---> software\n",
      "that ---> that\n",
      "accurately ---> accurately\n",
      "determines ---> determines\n",
      "the ---> the\n",
      "intended ---> intended\n",
      "meaning ---> meaning\n",
      "of ---> of\n",
      "text ---> text\n",
      "or ---> or\n",
      "voice ---> voice\n",
      "data ---> data\n",
      ". ---> .\n",
      "Homonyms ---> Homonyms\n",
      ", ---> ,\n",
      "homophones ---> homophone\n",
      ", ---> ,\n",
      "sarcasm ---> sarcasm\n",
      ", ---> ,\n",
      "idioms ---> idiom\n",
      ", ---> ,\n",
      "metaphors ---> metaphor\n",
      ", ---> ,\n",
      "grammar ---> grammar\n",
      "and ---> and\n",
      "usage ---> usage\n",
      "exceptions ---> exception\n",
      ", ---> ,\n",
      "variations ---> variation\n",
      "in ---> in\n",
      "sentence ---> sentence\n",
      "structure ---> structure\n",
      ". ---> .\n",
      "These ---> These\n",
      "just ---> just\n",
      "a ---> a\n",
      "few ---> few\n",
      "of ---> of\n",
      "the ---> the\n",
      "irregularities ---> irregularity\n",
      "of ---> of\n",
      "human ---> human\n",
      "language ---> language\n",
      "that ---> that\n",
      "take ---> take\n",
      "humans ---> human\n",
      "years ---> year\n",
      "to ---> to\n",
      "learn ---> learn\n",
      ", ---> ,\n",
      "but ---> but\n",
      "that ---> that\n",
      "programmers ---> programmer\n",
      "must ---> must\n",
      "teach ---> teach\n",
      "natural ---> natural\n",
      "language ---> language\n",
      "driven ---> driven\n",
      "applications ---> application\n",
      "to ---> to\n",
      "recognize ---> recognize\n",
      "and ---> and\n",
      "understand ---> understand\n",
      "accurately ---> accurately\n",
      "from ---> from\n",
      "the ---> the\n",
      "start ---> start\n",
      "if ---> if\n",
      "those ---> those\n",
      "applications ---> application\n",
      "are ---> are\n",
      "going ---> going\n",
      "to ---> to\n",
      "be ---> be\n",
      "useful ---> useful\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem= WordNetLemmatizer()\n",
    "\n",
    "for t in token:\n",
    "    print(t, '---> '+ lem.lemmatize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69483f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /home/student/.local/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>=3.8->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/student/.local/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/student/.local/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/student/.local/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.66.1)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m723.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929eb72f",
   "metadata": {},
   "source": [
    "# TextBlob Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfba6f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural ---> Natural\n",
      "language ---> language\n",
      "processing ---> processing\n",
      "refers ---> refers\n",
      "to ---> to\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "computer ---> computer\n",
      "science ---> science\n",
      "and ---> and\n",
      "more ---> more\n",
      "specifically ---> specifically\n",
      "the ---> the\n",
      "branch ---> branch\n",
      "of ---> of\n",
      "artificial ---> artificial\n",
      "intelligence ---> intelligence\n",
      "concerned ---> concerned\n",
      "with ---> with\n",
      "giving ---> giving\n",
      "computers ---> computer\n",
      "the ---> the\n",
      "ability ---> ability\n",
      "to ---> to\n",
      "understand ---> understand\n",
      "text ---> text\n",
      "and ---> and\n",
      "spoken ---> spoken\n",
      "words ---> word\n",
      "in ---> in\n",
      "much ---> much\n",
      "the ---> the\n",
      "same ---> same\n",
      "way ---> way\n",
      "human ---> human\n",
      "beings ---> being\n",
      "can ---> can\n",
      "Human ---> Human\n",
      "language ---> language\n",
      "is ---> is\n",
      "filled ---> filled\n",
      "with ---> with\n",
      "ambiguities ---> ambiguity\n",
      "that ---> that\n",
      "make ---> make\n",
      "it ---> it\n",
      "incredibly ---> incredibly\n",
      "difficult ---> difficult\n",
      "to ---> to\n",
      "write ---> write\n",
      "software ---> software\n",
      "that ---> that\n",
      "accurately ---> accurately\n",
      "determines ---> determines\n",
      "the ---> the\n",
      "intended ---> intended\n",
      "meaning ---> meaning\n",
      "of ---> of\n",
      "text ---> text\n",
      "or ---> or\n",
      "voice ---> voice\n",
      "data ---> data\n",
      "Homonyms ---> Homonyms\n",
      "homophones ---> homophone\n",
      "sarcasm ---> sarcasm\n",
      "idioms ---> idiom\n",
      "metaphors ---> metaphor\n",
      "grammar ---> grammar\n",
      "and ---> and\n",
      "usage ---> usage\n",
      "exceptions ---> exception\n",
      "variations ---> variation\n",
      "in ---> in\n",
      "sentence ---> sentence\n",
      "structure ---> structure\n",
      "These ---> These\n",
      "just ---> just\n",
      "a ---> a\n",
      "few ---> few\n",
      "of ---> of\n",
      "the ---> the\n",
      "irregularities ---> irregularity\n",
      "of ---> of\n",
      "human ---> human\n",
      "language ---> language\n",
      "that ---> that\n",
      "take ---> take\n",
      "humans ---> human\n",
      "years ---> year\n",
      "to ---> to\n",
      "learn ---> learn\n",
      "but ---> but\n",
      "that ---> that\n",
      "programmers ---> programmer\n",
      "must ---> must\n",
      "teach ---> teach\n",
      "natural ---> natural\n",
      "language ---> language\n",
      "driven ---> driven\n",
      "applications ---> application\n",
      "to ---> to\n",
      "recognize ---> recognize\n",
      "and ---> and\n",
      "understand ---> understand\n",
      "accurately ---> accurately\n",
      "from ---> from\n",
      "the ---> the\n",
      "start ---> start\n",
      "if ---> if\n",
      "those ---> those\n",
      "applications ---> application\n",
      "are ---> are\n",
      "going ---> going\n",
      "to ---> to\n",
      "be ---> be\n",
      "useful ---> useful\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob= TextBlob(text)\n",
    "\n",
    "for i in blob.words:\n",
    "    print(i, '---> '+ i.lemmatize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becf315",
   "metadata": {},
   "source": [
    "# Pattern Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae5cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pattern\n",
      "  Using cached Pattern-3.6.0.tar.gz (22.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting backports.csv (from pattern)\n",
      "  Using cached backports.csv-1.0.7-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (from pattern) (4.10.0)\n",
      "Collecting cherrypy (from pattern)\n",
      "  Using cached CherryPy-18.9.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting feedparser (from pattern)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from pattern) (0.18.2)\n",
      "Requirement already satisfied: lxml in /usr/lib/python3/dist-packages (from pattern) (4.8.0)\n",
      "Collecting mysqlclient (from pattern)\n",
      "  Using cached mysqlclient-2.2.4.tar.gz (90 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Trying pkg-config --exists mysqlclient\n",
      "  \u001b[31m   \u001b[0m Command 'pkg-config --exists mysqlclient' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m Trying pkg-config --exists mariadb\n",
      "  \u001b[31m   \u001b[0m Command 'pkg-config --exists mariadb' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m Trying pkg-config --exists libmariadb\n",
      "  \u001b[31m   \u001b[0m Command 'pkg-config --exists libmariadb' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/student/.local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/student/.local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/home/student/.local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-pfryq_en/overlay/local/lib/python3.10/dist-packages/setuptools/build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-pfryq_en/overlay/local/lib/python3.10/dist-packages/setuptools/build_meta.py\", line 295, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-pfryq_en/overlay/local/lib/python3.10/dist-packages/setuptools/build_meta.py\", line 311, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 155, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 49, in get_config_posix\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 28, in find_package_name\n",
      "  \u001b[31m   \u001b[0m Exception: Can not find valid pkg-config name.\n",
      "  \u001b[31m   \u001b[0m Specify MYSQLCLIENT_CFLAGS and MYSQLCLIENT_LDFLAGS env vars manually\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c134be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/student/.local/lib/python3.10/site-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m733.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "Successfully installed pip-24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a5f2eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5673/2415815707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexeme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"The bats saw the cats with best stripes hanging upside down by their feet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlemmatized_sentence\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern'"
     ]
    }
   ],
   "source": [
    "from pattern.en import lemma, lexeme, parse\n",
    "\n",
    "sentence= \"The bats saw the cats with best stripes hanging upside down by their feet\"\n",
    "lemmatized_sentence= \" \".join([lemma(word) for word in sentence.split()])\n",
    "print(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmas_for_each_word= [lexeme(wd) for wd in sentence.split()]\n",
    "print(all_lemmas_for_each_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
